{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d40c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image #image processing library \n",
    "import joblib\n",
    "\n",
    "# tensorflow imports for layers models and optimiser\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Flatten,BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from gandywarhol.data_gen import CustomDataGen # our custom data loader\n",
    "from tqdm.notebook import tqdm # makes progress bar\n",
    "from tensorflow.keras.utils import plot_model # allows picture view of model to see input and output size of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41440292",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128 # length and width of image\n",
    "IMAGE_CHANNELS = 3 # image depth (RGB)\n",
    "# Preview image Frame\n",
    "PREVIEW_ROWS = 4 # rows of images to be produced\n",
    "PREVIEW_COLS = 7 # columns of images to be produced therefore 28 images\n",
    "PREVIEW_MARGIN = 4 # 4 pixels between image \n",
    "\n",
    "# how often to save images\n",
    "SAVE_FREQ = 10\n",
    "\n",
    "# number of channels of noise to generate images from\n",
    "NOISE_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "GENERATE_RES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19881322",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = ['../raw_data/'+image for image in os.listdir('../raw_data') if image.endswith('jpeg')]\n",
    "train_set = CustomDataGen(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43d81d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26f146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2,\n",
    "    input_shape=image_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb9ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(noise_size, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4 * 4 * 256, activation='relu',       input_dim=noise_size))\n",
    "    model.add(Reshape((4, 4, 256)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    for i in range(GENERATE_RES):\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation('relu'))\n",
    "    model.summary()\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    input_ = Input(shape=(noise_size,))\n",
    "    generated_image = model(input_)\n",
    "    \n",
    "    return Model(input_, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5733c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt, noise, epoch):\n",
    "# image_array creates a white rectangle (255) of the size we need it in order to view our 28 images\n",
    "# The margin is the 4 pixels between each image     \n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "# This generates our 28 images, and then puts them between 0 and 1\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    image_count = 0\n",
    "# The following loop puts each image in its correct square. r takes the pixel on the far left of each square,\n",
    "# c takes the pixel at the top of each square and then starting there the image is placed, this loops through \n",
    "# for each image and its respective square it belongs. \n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c +\n",
    "                        IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "    output_path = 'output'\n",
    "# finally we save the picture of all 28 images in our desired place.\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n",
    "    fin_img_path = 'single_imgs'\n",
    "    if not os.path.exists(fin_img_path):\n",
    "        os.makedirs(fin_img_path)\n",
    "    if epoch == EPOCHS:\n",
    "        for i in range(28):\n",
    "            filename = os.path.join(fin_img_path, f\"final-{i}.png\")\n",
    "            im = Image.fromarray(generated_images[i]*255)\n",
    "            im.save(filename)\n",
    "            i += 1\n",
    "# We could edit this slightly so that it saved the epoch number and not just the count of how many images are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a65cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 16:35:13.420466: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 4096)              413696    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 8, 256)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 64, 64, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64, 64, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 128, 128, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128, 128, 256)    1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128, 128, 256)     0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,369,216\n",
      "Trainable params: 3,366,656\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS) # (128,128,3)\n",
    "\n",
    "# We use adam optimization\n",
    "optimizer = Adam(learning_rate = 1.5e-4,beta_1 = 0.5)\n",
    "\n",
    "# Simple discriminator loss since binary classifier and metric is accuracy since we are looking for accurate results.\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# for the generator we combine it with the disciminator before compiling \n",
    "\n",
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "random_input = Input(shape=(NOISE_SIZE,))\n",
    "generated_image = generator(random_input)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(generated_image)\n",
    "\n",
    "\n",
    "\n",
    "combined = Model(random_input, validity)\n",
    "\n",
    "combined.compile(loss='binary_crossentropy',\n",
    "optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40eae3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n",
      "resuffling data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         discriminator_metric_generated \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(\n\u001b[1;32m     18\u001b[0m         x_fake, y_fake) \u001b[38;5;66;03m# how good is discrim at detecting fake images\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         discriminator_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(discriminator_metric_real, discriminator_metric_generated)\n\u001b[0;32m---> 20\u001b[0m     generator_metric \u001b[38;5;241m=\u001b[39m \u001b[43mcombined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# how good is the generator at trying to produce real images \u001b[39;00m\n\u001b[1;32m     21\u001b[0m train_set\u001b[38;5;241m.\u001b[39mon_epoch_end() \u001b[38;5;66;03m# shuffle the images so the next epoch will have different batches \u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m SAVE_FREQ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# save images at desired intervals \u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/keras/engine/training.py:2093\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2089\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x,\n\u001b[1;32m   2090\u001b[0m                                                 y, sample_weight,\n\u001b[1;32m   2091\u001b[0m                                                 class_weight)\n\u001b[1;32m   2092\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2093\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2095\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/gandy_warhol/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first we set our y, simply 1 for real images and 0 for fake images\n",
    "y_real = np.ones((BATCH_SIZE, 1))\n",
    "y_fake = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "\n",
    "# instantiate 28 images of noise since we are creating 28 images with each predict \n",
    "# this noise stays fixed so that each image in each position is generated from same noise \n",
    "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    for index in range(len(train_set)): # note each iteration of for loop is one batch \n",
    "        x_real = train_set[index] # set image between (0,1)\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE)) # this is the noise to test our metric so isnt fixed\n",
    "        x_fake = generator.predict(noise) # create fake image\n",
    "        if epoch % 2 == 0:\n",
    "            discriminator_metric_real = discriminator.train_on_batch(x_real, y_real) # how good is discrim at real image\n",
    "            discriminator_metric_generated = discriminator.train_on_batch(\n",
    "            x_fake, y_fake) # how good is discrim at detecting fake images\n",
    "            discriminator_metric = 0.5 * np.add(discriminator_metric_real, discriminator_metric_generated)\n",
    "        generator_metric = combined.train_on_batch(noise, y_real) # how good is the generator at trying to produce real images \n",
    "    train_set.on_epoch_end() # shuffle the images so the next epoch will have different batches \n",
    "    if epoch % SAVE_FREQ == 0: # save images at desired intervals \n",
    "        save_images(cnt, fixed_noise, epoch)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25419d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
